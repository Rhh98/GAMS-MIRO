GAMS 31.1.0  r55b6ce3 Released May  1, 2020 WEX-WEI x86 64bit/MS Windows - 08/04/20 15:30:40 Page 1
G e n e r a l   A l g e b r a i c   M o d e l i n g   S y s t e m
C o m p i l a t i o n


   1  *
   2  scalar
   3  lam 'L2 regularization weight of learner' /0.001/,
   4  sigma 'RBF kernel bandwidth' /0.5/
   5  ;
       ----------------------------------------
       Generate "dirty" training data. 
       that is, we will plant some "historical bias" 
       in the form of labels: the Ministry of Magic refused to hire
       muggle-born graduates with high edcuation.
       
      data points are on a uniform grid, then dithered with a Guassian.
      x_1=magic heritage; x_2=education
  16   
  17  set p 'parameters to fit' /0,1*100/;
  18  set n(p) 'training set' /1*100/,
  19  aspect /Heritage,education/;
  20  *training data
  21  parameter
  22  X_Train(n,aspect)  'training data'
  23  ;
  24  alias(n,n1,n2,n3);
  25  X_Train(n,'Heritage')=0.1*ceil(n.val/10)-0.05;
  26  X_Train(n,'Education')=0.1*(n.val-floor((n.val-1)/10)*10)-0.05;
  27  display X_Train;
  28  *Training data dithered with a Gaussian
  29  X_Train(n,aspect)=X_Train(n,aspect)+0.03*normal(0,1);
  30  X_Train(n,aspect)$(X_Train(n,aspect) lt 0)=1e-5;
  31  X_Train(n,aspect)$(X_Train(n,aspect) gt 1)=1;
  32  *the noiseless 'desired' label obeys y_E=sign(X_E-0.5)
  33  parameter y_E(n);
  34  y_E(n)$(X_Train(n,'Education')-0.5 eq 0)=1;
  35  y_E(n)$(X_Train(n,'Education')-0.5 gt 0)=1;
  36  y_E(n)$(X_Train(n,'Education')-0.5 lt 0)=-1;
  37  *Contamination
  38  *The historically based rule is
  39  parameter y_Con(n);
  40  y_Con(n)=y_E(n);
  41  y_Con(n)$((X_Train(n,'Education') lt (4*sqr(X_Train(n,'Heritage')-0.5)+0.5))
  42   and (X_Train(n,'Heritage') lt 0.5) )=-1;
  43   
  44   
      % w is the debugging optimization variable, the special case for delta in
      % the binary classification case.
  49   
  50   
  51  variables w(n);
  52  parameter w_true(n)
  53  ;
  54  w.l(n)=0;
  55  w_true(n)$(y_Con(n) ne y_E(n))=1;
  56   
  57  *alpha's are the dual parameters in kernel logistic regression to be learned.
  58  parameter K(n,n) 'Kernel function';
  59  K(n,n1)=-(sqr(X_Train(n,'Heritage'))+sqr(X_Train(n,'Education')))-(sqr(X_Train(n1,'Heritage'))+sqr(X_Train(n1,'Education')))+
  60  2*(X_Train(n,'Heritage')*X_Train(n1,'Heritage')+X_Train(n,'Education')*X_Train(n1,'Education'));
  61  K(n,n1)=exp(K(n,n1)/(2*sqr(sigma)));
  62   
  63  *Binary kernel logistic ridge regression
  64   
  65   
  66  *Lower level problem
  67  variables alpha(p),log_l(n),obj_In;
  68  equations deflog_l(n),defobj_In;
  69   
  70  deflog_l(n)..
  71  log_l(n) =e=  -y_Con(n)*(sum(n1,K(n,n1)*alpha(n1))+alpha('0'));
  72   
  73  defobj_In..
  74  obj_In =e= lam/2*sum(n,sum(n1,K(n,n1)*alpha(n)*alpha(n1)))
  75      + 1/card(n)*sum(n,(1-w(n))*log(1+exp(log_l(n)))+w(n)*log(1+exp(-log_l(n))));
  76   
  77  alpha.l(n)=0;
  78  model submodel /defobj_In,deflog_l/;
  79  * MCF: should this be w_true?
  80  w.fx(n) = w.l(n);
  81  solve submodel using nlp minimizing obj_In;
  82   
  83  *generated trusted data--------------------
  84  set Header;
  85  ;
  86  Set T_column /heritage,education,label/;
  88  table Trust_info(Header<,T_column) Information of Trusted Item
  89        heritage   education  label
  90  1     0.3        0.4        -1
  91  2     0.2        0.6        1
  92  ;
  93  scalar gamma  Label changing panelty /200/;
  94   
  96   
  97  *scalar gamma2;
  98  *gamma2=gamma;
  99  parameter Trust_data(Header,aspect),Trust_label(Header);
 100  Trust_data(Header,'heritage')=Trust_info(Header,'heritage');
 101  Trust_data(Header,'education')=Trust_info(Header,'education');
 102  Trust_label(Header)=Trust_info(Header,'label');
 103  parameter c(header) /set.header 100/;
 104   
 105  *Generating contour by kernel logistic regression
 106  parameter Z(n,n) 'label of testing data (0.01:0.01:1,0.01:0.01,1)',
 107  temp(n,n,n)  'temporary value',
 108  e(n,n), d(n,n)  'mesh grid'
 109  ;
 110  e(n,n1)=0.01*n1.val;
 111  d(n,n1)=0.01*n.val;
 112  temp(n,n1,n2)=-(sqr(X_Train(n2,'Heritage'))+sqr(X_Train(n2,'Education')))-(sqr(e(n,n1))+sqr(d(n,n1)))
 113  +2*(e(n,n1)*X_Train(n2,'Heritage')+d(n,n1)*X_Train(n2,'Education'));
 114  temp(n,n1,n2)=exp(temp(n,n1,n2)/(2*sigma*sigma));
 115  Z(n,n1)=sum(n2,temp(n,n1,n2)*alpha.l(n2))+alpha.l('0');
 116  display Z;
 117   
 118   
 119  scalar budget /20/;
 120  parameter K_tilde(Header,n);
 121  alias(Header,Header2);
 122  K_tilde(Header,n)=-sum(aspect,sqr(trust_data(Header,aspect)))-(sqr(X_Train(n,'Heritage'))+sqr(X_Train(n,'Education')))
 123  +2*(trust_data(Header,'heritage')*X_Train(n,'Heritage')+trust_data(Header,'education')*X_Train(n,'Education'));
 124  K_tilde(Header,n)=exp(K_tilde(Header,n)/(2*sigma*sigma));
 125   
 126  *outter level problem
 127  variables log_l2(Header),obj;
 128  equations defobj,deflog_l2(Header);
 129   
 130  deflog_l2(Header)..
 131  log_l2(Header) =e= -Trust_label(Header)*(sum(n1,K_tilde(Header,n1)*alpha(n1))+alpha('0'));
 132  defobj..
 133  obj =e= gamma/card(n)*sum(n,w(n)) +1/card(Header)*sum(Header,c(Header)*log(1+exp(log_l2(Header))))+1/card(n)*sum(n,(1-w(n))*log(1+exp(log_l(n))+w(n)*log(1+exp(-log_l(n)))));
 134   
 135  model Kernel_duti /submodel,deflog_l2,defobj/;
 136  File myinfo / 'C:\Users\hasee\Documents\GitHub\GAMS-MIRO\HarryPotter\225a\empinfo.dat' /;
 137  put myinfo "bilevel" /;
 138  putclose "min obj_In log_l alpha deflog_l defobj_In"/;
 139   
      $echo subsolver knitro>jams.opt
      Kernel_duti.optcr=1e-1;
      Kernel_duti.optfile=1;
 152   
 153  * for baron and knitro
 154  alpha.lo(p) = -100;
 155  alpha.up(p) = 100;
 156  log_l.lo(n) = -10;
 157  log_l.up(n) = 10;
 158  log_l2.lo(Header) = -10;
 159  log_l2.up(Header) = 10;
 160   
 161  *option dnlp=baron;
 162  *$echo subsolver nlpec>jams.opt
 163   
 164  option mpec = knitro;
 165  *Kernel_duti.optfile=1;
 166   
 167  w.fx(n) = 0;
 168  solve submodel using nlp minimizing obj_In;
 169  w.lo(n) = 0;
 170  w.up(n) = 1;
 171  *w.fx('91')=0;
 172  *w.fx('94')=0;
 173  solve Kernel_duti using emp minimizing obj;
 174   
 175  set g /g1*g40/;
 176  parameter ranking(n);
 177  scalar num /0/,
 178  threshold /0.5/;
 179  ranking(n)=card(g)+1;
 180  ranking(n)$(ranking(n) eq card(g)+1 and w.l(n)>threshold)=w.l(n);
 181  num=sum(n$(ranking(n) ne card(g)+1) ,1);
      loop(g$(num < budget),
      gamma2=gamma2/2;
      if(ord(g)eq card(g),gamma2=0;);
      solve Kernel_duti using emp minimizing obj;
      ranking(n)$(ranking(n) eq card(g)+1 and w.l(n)>threshold)=ord(g)+1-w.l(n);
      num=sum(n$(ranking(n) ne card(g)+1) ,1);
      );
       
 192   
 193  *boundary and debug output
 194  set output1Header /heritage,education,val label of training data,Zval,newz,heritage_T,education_T,label label of trust data,ranking/;
 196  table Output1(n,n1,Header,output1Header);
 197  Output1(n,n1,Header,'heritage')$(ord(n1)=1 and ord(Header)=1)=X_Train(n,'heritage');
 198  Output1(n,n1,Header,'education')$(ord(n1)=1 and ord(Header)=1)=X_Train(n,'education');
 199  Output1(n,n1,Header,'val')$(ord(n1)=1 and ord(Header)=1)=y_Con(n);
 200  Output1(n,n1,Header,'zval')$(ord(Header)=1)=Z(n,n1);
 201  Output1(n,n1,Header,'heritage_T')$(ord(n1)=1 and ord(n)=1)=Trust_data(Header,'heritage');
 202  Output1(n,n1,Header,'education_T')$(ord(n1)=1 and ord(n)=1)=Trust_data(Header,'education');
 203  Output1(n,n1,Header,'label')$(ord(n1)=1 and ord(n)=1)=Trust_label(Header);
 204  Output1(n,n1,Header,'ranking')$(ord(n1)=1 and ord(Header)=1)=ranking(n);
 205  Output1(n,n1,Header,'newz')$(ord(Header)=1)=sum(n2,temp(n,n1,n2)*alpha.l(n2))+alpha.l('0');
 207  display ranking;
 208  parameter newz(n,n);
 209  newZ(n,n1)=sum(n2,temp(n,n1,n2)*alpha.l(n2))+alpha.l('0');


COMPILATION TIME     =        0.297 SECONDS      3 MB  31.1.0 r55b6ce3 WEX-WEI


USER: Michael Ferris Research Group - Eval           G191008/0001AS-GEN
      UW-Madison Computer Sciences Dept.                         DCE244
      License for teaching and research at degree granting institutions


**** FILE SUMMARY

Input      C:\Users\hasee\Documents\GitHub\GAMS-MIRO\HarryPotter\HarryPotter_emp.gms
Output     C:\Users\hasee\Documents\GitHub\GAMS-MIRO\HarryPotter\HarryPotter_emp.lst
